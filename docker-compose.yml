version: '3.8'

services:
  # --- Zookeeper for Kafka ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -z localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- Kafka Broker ---
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- Cassandra Database ---
  cassandra:
    image: cassandra:4.1
    hostname: cassandra
    container_name: cassandra
    ports:
      - "9042:9042" # CQL native port
    environment:
      CASSANDRA_CLUSTER_NAME: 'MySparkCassandraCluster'
      CASSANDRA_NUM_TOKENS: 256
      CASSANDRA_DC: 'datacenter1'
      CASSANDRA_RACK: 'rack1'
    volumes:
      - cassandra_data:/var/lib/cassandra
    healthcheck:
      test: ["CMD-SHELL", "cqlsh --debug cassandra -e 'describe cluster;'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    restart: always

  # --- Spark Master ---
  spark-master:
    # image: bitnami/spark:3.5.0 # Using Bitnami image which includes pre-installed dependencies
    build:
      context: .
      dockerfile: dockerfiles/spark/Dockerfile
      args:
        SPARK_VERSION: 3.5.0
        SPARK_SCALA_VERSION: 2.12
    hostname: spark-master
    container_name: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    ports:
      - "8080:8080" # Spark Master Web UI
      - "7077:7077" # Spark Master internal communication
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no" # For simplicity in dev
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_DIRS: /tmp/spark
      SPARK_LOG_LEVEL: INFO # Or WARN/ERROR for less verbosity
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/jobs # Mount your Spark jobs
      - ./data:/opt/bitnami/spark/data # Mount your data folder for Spark access
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O /dev/null http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # --- Spark Worker 1 ---
  spark-worker-1: # Renamed from spark-worker
    build:
      context: .
      dockerfile: dockerfiles/spark/Dockerfile
      args:
        SPARK_VERSION: 3.5.0
        SPARK_SCALA_VERSION: 2.12
    hostname: spark-worker-1 # Unique hostname
    container_name: spark-worker-1 # Unique container name
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 2G
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_DIRS: /tmp/spark
      SPARK_LOG_LEVEL: INFO
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/jobs
      - ./data:/opt/bitnami/spark/data
    # depends_on:
    #   spark-master:
    #     condition: service_healthy # Re-enabled depends_on
    # healthcheck:
    #   test: ["CMD-SHELL", "wget -q -O /dev/null http://spark-master:8080"] # Re-enabled healthcheck
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5

  # --- Spark Worker 2 ---
  spark-worker-2: # New worker service
    build:
      context: .
      dockerfile: dockerfiles/spark/Dockerfile
      args:
        SPARK_VERSION: 3.5.0
        SPARK_SCALA_VERSION: 2.12
    hostname: spark-worker-2
    container_name: spark-worker-2
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 2G
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_DIRS: /tmp/spark
      SPARK_LOG_LEVEL: INFO
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/jobs
      - ./data:/opt/bitnami/spark/data
    # depends_on:
    #   spark-master:
    #     condition: service_healthy
    # healthcheck:
    #   test: ["CMD-SHELL", "wget -q -O /dev/null http://spark-master:8080"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5

  # --- Spark Worker 3 ---
  spark-worker-3: # New worker service
    build:
      context: .
      dockerfile: dockerfiles/spark/Dockerfile
      args:
        SPARK_VERSION: 3.5.0
        SPARK_SCALA_VERSION: 2.12
    hostname: spark-worker-3
    container_name: spark-worker-3
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 2G
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_DIRS: /tmp/spark
      SPARK_LOG_LEVEL: INFO
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/jobs
      - ./data:/opt/bitnami/spark/data
    # depends_on:
    #   spark-master:
    #     condition: service_healthy
    # healthcheck:
    #   test: ["CMD-SHELL", "wget -q -O /dev/null http://spark-master:8080"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5

  api:
    build:
      context: .
      dockerfile: ./api/Dockerfile_API
    hostname: data-api
    container_name: data-api
    ports:
      - "5000:5000"
    volumes:
      - ./data:/app/data
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- Streamlit Dashboard ---
  dashboard:
    build:
      context: . # Build from the dashboard directory
      dockerfile: ./dashboard/Dockerfile_Dashboard # Specify custom Dockerfile name
    hostname: streamlit-dashboard
    container_name: streamlit-dashboard
    ports:
      - "8501:8501" # Default Streamlit port
    depends_on:
      kafka:
        condition: service_healthy
    restart: always

  cassandra-setup:
    build:
      context: ./db_setup # Build from the db_setup directory
      dockerfile: Dockerfile_CassandraSetup # Specify custom Dockerfile name
    container_name: cassandra-setup
    depends_on:
      cassandra:
        condition: service_healthy # Ensure Cassandra is ready before running setup
    restart: "no" # Only run once and exit
    volumes:
      # Optional: Mount your db_setup directory if you want to make changes without rebuilding image
      - ./db_setup:/app

volumes:
  cassandra_data: # For Cassandra persistent data