# spark_jobs/process_test_data.py (UPDATED for Dynamic Model Reloading and Metrics)

from pyspark.sql import SparkSession
import pyspark.sql.functions as F
from pyspark.sql.functions import from_json, col, current_timestamp, udf
from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, TimestampType, FloatType # Added IntegerType
from pyspark.ml import PipelineModel
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from datetime import datetime
import logging
import uuid
import os
import time # For checking file modification time
from pyspark.ml.linalg import Vector # Make sure this import is present at the top
# from pyspark.sql.types import DoubleType # For the UDF return type (already imported above)

# Define a UDF to extract the positive probability (assuming it's at index 1)
# This UDF will receive the pyspark.ml.linalg.Vector object directly
@udf(DoubleType())
def get_positive_probability_udf(vec: Vector) -> float:
    if vec is None:
        return None
    # Assuming the positive class probability is at index 1 of the probability vector
    # Spark ML classifiers typically output probabilities for each class,
    # with the index corresponding to the indexed label (e.g., 0 for negative, 1 for positive, 2 for neutral)
    if len(vec) > 1: # Ensure the vector has at least two elements
        return float(vec[1])
    return None # Or handle as appropriate if vector is too short

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Spark Session Configuration ---
SPARK_PACKAGES = "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0"

spark = SparkSession.builder \
    .appName("KafkaTestDataProcessorAndPredictor") \
    .config("spark.jars.packages", SPARK_PACKAGES) \
    .config("spark.cassandra.connection.host", "cassandra") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")
logger.info("Spark Session for Test Data Processor created.")

# --- Configuration Variables ---
MODEL_PATH = "/opt/bitnami/spark/jobs/model/sentiment_model" # Shared volume path for model
KAFKA_BOOTSTRAP_SERVERS = "kafka:29092"
RAW_TEST_TOPIC = "raw_test_data"
PREDICTED_KAFKA_TOPIC = "predicted_test_data"
REALTIME_METRICS_TOPIC = "realtime_metrics"
CASSANDRA_PREDICTED_KEYSPACE = "my_project_keyspace"
CASSANDRA_PREDICTED_TABLE = "predicted_data_results"

# --- Global variable to hold the model and its last loaded timestamp ---
# This allows us to reload the model periodically
current_model = None
last_model_load_time = None

def load_latest_model():
    """Loads the ML model from the specified path."""
    global current_model, last_model_load_time
    
    if not os.path.exists(MODEL_PATH):
        logger.error(f"Model path {MODEL_PATH} does not exist. Cannot load model.")
        current_model = None
        last_model_load_time = None
        return

    # Get the last modification time of the model directory
    # os.path.getmtime returns seconds since epoch
    model_dir_mtime = os.path.getmtime(MODEL_PATH)
    
    # Only reload if the model file is newer than the last loaded time
    # or if no model has been loaded yet.
    if current_model is None or model_dir_mtime > (last_model_load_time or 0):
        try:
            logger.info(f"Loading/reloading ML model from {MODEL_PATH} (modified: {datetime.fromtimestamp(model_dir_mtime)})...")
            new_model = PipelineModel.load(MODEL_PATH)
            current_model = new_model
            last_model_load_time = model_dir_mtime
            logger.info("Machine Learning Model loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load/reload ML model from {MODEL_PATH}: {e}", exc_info=True)
            current_model = None # Ensure model is None if loading fails
    else:
        logger.debug("Model file not updated. Using current model.")

# --- Define Schema for Incoming Test Data from Kafka ---
test_data_kafka_schema = StructType([
    StructField("id", StringType(), True),         # UUID generated by producer
    StructField("comment", StringType(), True),
    StructField("n_star", IntegerType(), True),
    StructField("date_time", StringType(), True),
    StructField("label", StringType(), True),
])

# UDF to generate a UUID (though producer provides it, this is fallback/consistency)
generate_uuid_udf = udf(lambda: str(uuid.uuid4()), StringType())

# --- Metrics UDF for consistent label mapping ---
# This UDF should mirror the labels used in your StringIndexer in train_model.py
# and their assigned indices.
# Assuming label_indexer.labels = ['negative', 'positive', 'neutral'] based on sorted unique labels
label_mapping = {
    'negative': 0,
    'positive': 1,
    'neutral': 2
}
label_to_int_udf = udf(lambda label_str: label_mapping.get(label_str, -1), IntegerType())

logger.info(f"Reading stream from Kafka topic: {RAW_TEST_TOPIC}")

# Read data from Kafka (raw_test_data topic)
kafka_df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", KAFKA_BOOTSTRAP_SERVERS) \
    .option("subscribe", RAW_TEST_TOPIC) \
    .option("startingOffsets", "latest") \
    .load()

# Parse the JSON 'value' from Kafka, cast date_time to Timestamp, add processing_timestamp
parsed_test_df = kafka_df.selectExpr("CAST(value AS STRING)") \
    .select(from_json(col("value"), test_data_kafka_schema).alias("data")) \
    .select("data.*") \
    .withColumn("id", col("id")) \
    .withColumn("date_time", col("date_time").cast(TimestampType())) \
    .withColumn("processing_timestamp", current_timestamp())


# --- ForeachBatch Function for Processing and Saving ---
def process_batch_with_model(batch_df, batch_id):
    if batch_df.count() == 0:
        logger.debug(f"Batch {batch_id}: No records in batch. Skipping.")
        return

    # Check for and load latest model before processing each batch
    load_latest_model()

    if current_model is None:
        logger.error(f"Batch {batch_id}: No model available for predictions. Skipping batch.")
        return

    logger.info(f"Batch {batch_id}: Processing {batch_df.count()} records with model.")
    
    try:
        # Make Predictions using the Loaded Model
        predictions_df = current_model.transform(batch_df)

        # Add numeric true label for evaluation
        predictions_df = predictions_df.withColumn("indexed_true_label", label_to_int_udf(col("label")))

        # Prepare data for Kafka and Cassandra output
        output_prepared_df = predictions_df.select(
            "id",
            "comment",
            "n_star",
            "date_time",
            "label", # True label (from Kafka input)
            # Corrected: Cast prediction to IntegerType to match Cassandra's 'int'
            F.col("prediction").cast(IntegerType()).alias("predicted_label_index"),
            F.col("predicted_composite_label").alias("predicted_sentiment_string"), # Human-readable predicted label
            F.col("rawPrediction").cast(StringType()).alias("raw_prediction"), # Convert vector to string for Cassandra
            # Using the new UDF for positive_probability
            # get_positive_probability_udf(F.col("probability")).alias("positive_probability"),
            "processing_timestamp" # Include processing timestamp
        )

        # --- Write Predictions to Kafka ---
        logger.info(f"Batch {batch_id}: Writing predictions to Kafka topic: {PREDICTED_KAFKA_TOPIC}")
        output_prepared_df \
            .selectExpr("CAST(id AS STRING) AS key", "to_json(struct(*)) AS value") \
            .write \
            .format("kafka") \
            .option("kafka.bootstrap.servers", KAFKA_BOOTSTRAP_SERVERS) \
            .option("topic", PREDICTED_KAFKA_TOPIC) \
            .save() # Use .save() for batch writes within foreachBatch

        # --- Write Predictions to Cassandra ---
        logger.info(f"Batch {batch_id}: Writing predictions to Cassandra: {CASSANDRA_PREDICTED_KEYSPACE}.{CASSANDRA_PREDICTED_TABLE}")
        # Cassandra uses primary key 'id' to handle upserts (no duplicates)
        output_prepared_df.write \
            .format("org.apache.spark.sql.cassandra") \
            .mode("append") \
            .options(table=CASSANDRA_PREDICTED_TABLE, keyspace=CASSANDRA_PREDICTED_KEYSPACE) \
            .save()

        # --- Real-time Metrics Calculation and Output ---
        logger.info(f"Batch {batch_id}: Calculating metrics for {batch_df.count()} records.")
        evaluator_accuracy = MulticlassClassificationEvaluator(labelCol="indexed_true_label", predictionCol="prediction", metricName="accuracy")
        evaluator_f1 = MulticlassClassificationEvaluator(labelCol="indexed_true_label", predictionCol="prediction", metricName="f1")

        accuracy = evaluator_accuracy.evaluate(predictions_df)
        f1_score = evaluator_f1.evaluate(predictions_df)
        logger.info(f"Batch {batch_id} Metrics: Accuracy={accuracy:.4f}, F1-score={f1_score:.4f}")

        # Prepare metrics for Kafka
        metrics_data = {
            "batch_id": batch_id,
            "timestamp": datetime.now().isoformat(),
            "total_records": predictions_df.count(),
            "accuracy": float(accuracy),
            "f1_score": float(f1_score)
        }
        metrics_df = spark.createDataFrame([metrics_data])
        metrics_df.selectExpr("to_json(struct(*)) AS value") \
            .write \
            .format("kafka") \
            .option("kafka.bootstrap.servers", KAFKA_BOOTSTRAP_SERVERS) \
            .option("topic", REALTIME_METRICS_TOPIC) \
            .save()

    except Exception as e:
        logger.error(f"Batch {batch_id}: Error processing batch or writing outputs: {e}", exc_info=True)


# --- Apply the foreachBatch sink to the streaming DataFrame ---
query_test_processor = parsed_test_df.writeStream \
    .foreachBatch(process_batch_with_model) \
    .option("checkpointLocation", os.path.join("/tmp/spark/checkpoints", RAW_TEST_TOPIC + "_processor_checkpoint")) \
    .trigger(processingTime="5 seconds") \
    .start()

logger.info("Spark Structured Streaming query for Test Data Processor started.")

# Await termination to keep the Spark application running
query_test_processor.awaitTermination()

spark.stop()
logger.info("Spark Session stopped.")